# ğŸ“ˆ Stock Market Data Engineering Pipeline

This project builds a production-ready stock market data pipeline that extracts daily stock price snapshots, loads them into Snowflake, and models the data using dbt for analytics and dashboarding.

---

## ğŸš€ Tech Stack

- **Airflow** (with Astronomer Cosmos)
- **dbt** (Data Build Tool for transformations)
- **Snowflake** (Cloud Data Warehouse)
- **Polygon.io API** (Daily stock market data)
- **Python**
- **.env-based secrets loading**

---

## âš™ï¸ Pipeline Overview

- Daily data pulled from Polygon API
- Stored in Snowflake (`stock_prices` + `tickers`)
- dbt transforms and snapshots historical metadata
- Aggregated marts for analytics and dashboarding
- Skips holidays / non-trading days with `AirflowSkipException`
- Partitioned tables + incremental models for performance

---

## ğŸ§  Key Features

âœ… Daily stock ingestion with Airflow  
âœ… Incremental & partitioned dbt models  
âœ… Historical ticker snapshots with `dbt snapshot`  
âœ… Aggregated marts for dashboarding:  
&nbsp;&nbsp;&nbsp;&nbsp;â€¢ Market Summary  
&nbsp;&nbsp;&nbsp;&nbsp;â€¢ Daily Metrics  
&nbsp;&nbsp;&nbsp;&nbsp;â€¢ Gainers/Losers  
âœ… Cosmos-managed `DbtTaskGroup`  
âœ… Modular code + reusable pipeline

---

## ğŸ“Š DAG Graph View

This is how the pipeline orchestrates daily tasks using Airflow:

![stocks_daily_dag_graph](images/stocks_daily_dag_graph.png)

> `load_prices` and `load_tickers_snapshot` pull data â†’  
> `dbt_run_marts` transforms raw data to marts via dbt  
> (including snapshots, aggregations, and tests)

---

## ğŸ—ƒï¸ Folder Structure

